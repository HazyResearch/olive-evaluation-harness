nohup: ignoring input
2024-04-30:00:38:21,102 INFO     [__main__.py:206] Verbosity set to INFO
2024-04-30:00:38:21,102 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.
2024-04-30:00:38:26,740 INFO     [__main__.py:282] Selected Tasks: ['hotpot_qa']
2024-04-30:00:38:26,740 INFO     [__main__.py:283] Loading selected tasks...
2024-04-30:00:38:26,742 INFO     [evaluator.py:95] Setting random seed to 0
2024-04-30:00:38:26,742 INFO     [evaluator.py:99] Setting numpy seed to 1234
2024-04-30:00:38:26,743 INFO     [evaluator.py:103] Setting torch manual seed to 1234
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-04-30:00:38:53,935 WARNING  [huggingface.py:117] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
2024-04-30:00:38:53,951 WARNING  [huggingface.py:328] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
2024-04-30:00:38:53,953 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage
2024-04-30:00:38:56,043 WARNING  [task.py:309] [Task: hotpot_qa] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-04-30:00:38:56,043 WARNING  [task.py:309] [Task: hotpot_qa] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2024-04-30:00:38:56,251 WARNING  [evaluator.py:182] Overwriting default num_fewshot of hotpot_qa from None to 0
2024-04-30:00:38:56,258 INFO     [task.py:362] Building contexts for hotpot_qa on rank 0...
2024-04-30:00:38:56,993 INFO     [evaluator.py:373] Running generate_until requests
Loading weights from /var/cr01_data/sabri_data/checkpoints/m04d18_wikipedia_flash_universal/wikipedia_flash_gpt_pythia-410m_pretrained/tzwzrz5v/last.ckpt
Checkpoint Path: /var/cr01_data/sabri_data/checkpoints/m04d25_hotpotqa_pretraining/continued_wikipedia_flash_gpt_pythia-410m_pretrained/w20wh2ul
  0%|          | 0/1000 [00:00<?, ?it/s]  0%|          | 1/1000 [01:20<22:13:45, 80.11s/it]  1%|          | 11/1000 [01:20<1:26:32,  5.25s/it]  2%|â–         | 22/1000 [01:20<34:45,  2.13s/it]    3%|â–Ž         | 32/1000 [01:20<19:28,  1.21s/it]  4%|â–         | 43/1000 [01:20<11:29,  1.39it/s]  5%|â–Œ         | 54/1000 [01:20<07:14,  2.18it/s]  6%|â–‹         | 65/1000 [01:20<04:44,  3.28it/s]  8%|â–Š         | 76/1000 [01:20<03:11,  4.82it/s]  9%|â–Š         | 87/1000 [01:20<02:11,  6.93it/s] 10%|â–‰         | 98/1000 [01:21<01:32,  9.78it/s] 11%|â–ˆ         | 109/1000 [01:21<01:05, 13.58it/s] 12%|â–ˆâ–        | 120/1000 [01:21<00:47, 18.51it/s] 13%|â–ˆâ–Ž        | 128/1000 [01:38<00:47, 18.51it/s] 13%|â–ˆâ–Ž        | 129/1000 [02:15<23:32,  1.62s/it] 14%|â–ˆâ–        | 139/1000 [02:15<16:27,  1.15s/it] 15%|â–ˆâ–Œ        | 150/1000 [02:15<11:08,  1.27it/s] 16%|â–ˆâ–Œ        | 160/1000 [02:15<07:50,  1.78it/s] 17%|â–ˆâ–‹        | 171/1000 [02:15<05:21,  2.58it/s] 18%|â–ˆâ–Š        | 182/1000 [02:15<03:41,  3.70it/s] 19%|â–ˆâ–‰        | 193/1000 [02:15<02:33,  5.25it/s] 20%|â–ˆâ–ˆ        | 203/1000 [02:16<01:51,  7.16it/s] 21%|â–ˆâ–ˆâ–       | 213/1000 [02:16<01:20,  9.76it/s] 22%|â–ˆâ–ˆâ–       | 223/1000 [02:16<00:59, 13.15it/s] 23%|â–ˆâ–ˆâ–Ž       | 234/1000 [02:16<00:42, 18.11it/s] 24%|â–ˆâ–ˆâ–       | 245/1000 [02:16<00:31, 24.29it/s] 26%|â–ˆâ–ˆâ–Œ       | 256/1000 [02:16<00:23, 31.65it/s] 26%|â–ˆâ–ˆâ–Œ       | 256/1000 [02:28<00:23, 31.65it/s] 26%|â–ˆâ–ˆâ–Œ       | 257/1000 [03:11<26:28,  2.14s/it] 27%|â–ˆâ–ˆâ–‹       | 267/1000 [03:11<16:55,  1.39s/it] 28%|â–ˆâ–ˆâ–Š       | 278/1000 [03:11<10:45,  1.12it/s] 29%|â–ˆâ–ˆâ–‰       | 289/1000 [03:11<07:02,  1.68it/s] 30%|â–ˆâ–ˆâ–ˆ       | 300/1000 [03:12<04:43,  2.47it/s] 31%|â–ˆâ–ˆâ–ˆ       | 310/1000 [03:12<03:18,  3.48it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 321/1000 [03:12<02:15,  5.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 332/1000 [03:12<01:33,  7.16it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 343/1000 [03:12<01:05, 10.04it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 354/1000 [03:12<00:46, 13.86it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 365/1000 [03:12<00:33, 18.80it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 376/1000 [03:12<00:25, 24.95it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 384/1000 [03:28<00:24, 24.95it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 385/1000 [04:06<16:15,  1.59s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 396/1000 [04:06<10:59,  1.09s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 407/1000 [04:06<07:29,  1.32it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 418/1000 [04:06<05:07,  1.89it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 429/1000 [04:06<03:31,  2.70it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 440/1000 [04:06<02:26,  3.83it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 451/1000 [04:06<01:41,  5.40it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 462/1000 [04:07<01:11,  7.56it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 473/1000 [04:07<00:50, 10.48it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 484/1000 [04:07<00:35, 14.36it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 495/1000 [04:07<00:26, 19.19it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 505/1000 [04:07<00:20, 24.52it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 512/1000 [04:18<00:19, 24.52it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 513/1000 [05:04<14:18,  1.76s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 523/1000 [05:04<09:48,  1.23s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 534/1000 [05:04<06:31,  1.19it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 544/1000 [05:04<04:31,  1.68it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 554/1000 [05:05<03:07,  2.37it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 564/1000 [05:05<02:10,  3.34it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 574/1000 [05:05<01:30,  4.70it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 584/1000 [05:05<01:03,  6.57it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 594/1000 [05:05<00:44,  9.11it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 604/1000 [05:05<00:31, 12.49it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614/1000 [05:05<00:22, 16.90it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 625/1000 [05:05<00:16, 23.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 636/1000 [05:05<00:11, 30.43it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 640/1000 [05:18<00:11, 30.43it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 641/1000 [06:03<11:44,  1.96s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 652/1000 [06:03<07:27,  1.29s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 662/1000 [06:03<05:00,  1.12it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 673/1000 [06:03<03:16,  1.67it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 683/1000 [06:03<02:14,  2.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 694/1000 [06:03<01:29,  3.43it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 704/1000 [06:03<01:01,  4.78it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 714/1000 [06:03<00:43,  6.65it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 725/1000 [06:03<00:29,  9.45it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 736/1000 [06:04<00:20, 13.18it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 747/1000 [06:04<00:14, 17.84it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 757/1000 [06:04<00:10, 23.31it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 767/1000 [06:04<00:07, 29.96it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 768/1000 [06:18<00:07, 29.96it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 769/1000 [07:00<08:27,  2.20s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 779/1000 [07:01<05:14,  1.42s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 790/1000 [07:01<03:12,  1.09it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 800/1000 [07:01<02:06,  1.58it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 810/1000 [07:01<01:23,  2.28it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 820/1000 [07:01<00:55,  3.26it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 830/1000 [07:01<00:36,  4.62it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 840/1000 [07:01<00:24,  6.50it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 850/1000 [07:01<00:16,  9.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 861/1000 [07:01<00:10, 12.79it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 871/1000 [07:02<00:07, 17.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 882/1000 [07:02<00:05, 23.36it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 892/1000 [07:02<00:03, 30.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 896/1000 [07:18<00:03, 30.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 897/1000 [07:57<03:18,  1.93s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 908/1000 [07:57<01:55,  1.25s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 918/1000 [07:57<01:10,  1.16it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 928/1000 [07:57<00:43,  1.67it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 939/1000 [07:57<00:24,  2.46it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 950/1000 [07:57<00:14,  3.57it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 961/1000 [07:57<00:07,  5.11it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 972/1000 [07:58<00:03,  7.23it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 983/1000 [07:58<00:01, 10.09it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 994/1000 [07:58<00:00, 13.90it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [07:58<00:00,  2.09it/s]
olive (checkpoint_name=hazy-research/olive/w20wh2ul), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 128
|  Tasks  |Version|Filter|n-shot|Metric|Value|   |Stderr|
|---------|------:|------|-----:|------|----:|---|------|
|hotpot_qa|      1|none  |     0|f1    |    0|Â±  |N/A   |

wandb: Currently logged in as: seyuboglu (hazy-research). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /var/cr05_data/sabri/jonsf/olive/olive-evaluation-harness/wandb/run-20240430_004703-7qpxkduy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hotpot_qa-continued_wikipedia_flash_gpt_pythia-410m_pretrained
wandb: â­ï¸ View project at https://wandb.ai/hazy-research/olive-eval
wandb: ðŸš€ View run at https://wandb.ai/hazy-research/olive-eval/runs/7qpxkduy
wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.015 MB uploadedwandb: | 0.015 MB of 0.015 MB uploadedwandb: / 0.050 MB of 0.066 MB uploaded (0.003 MB deduped)wandb: - 0.050 MB of 0.066 MB uploaded (0.003 MB deduped)wandb: \ 0.066 MB of 0.066 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 4.4%             
wandb: 
wandb: Run history:
wandb: hotpot_qa/f1,none â–
wandb: 
wandb: Run summary:
wandb:          hotpot_qa/alias hotpot_qa
wandb:        hotpot_qa/f1,none 0.0
wandb: hotpot_qa/f1_stderr,none N/A
wandb: 
wandb: ðŸš€ View run hotpot_qa-continued_wikipedia_flash_gpt_pythia-410m_pretrained at: https://wandb.ai/hazy-research/olive-eval/runs/7qpxkduy
wandb: â­ï¸ View project at: https://wandb.ai/hazy-research/olive-eval
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20240430_004703-7qpxkduy/logs
Running sweep with 1 configs
